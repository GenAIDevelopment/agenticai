{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0654e16d",
   "metadata": {},
   "source": [
    "## Output parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a77c12e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b8023a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_32140\\3513586721.py:1: DeprecationWarning: Use [`ChatGoogleGenerativeAI`][langchain_google_genai.ChatGoogleGenerativeAI] instead.\n",
      "  llm = ChatVertexAI(model_name=\"gemini-2.5-flash-lite\")\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_32140\\3513586721.py:1: LangChainDeprecationWarning: The class `ChatVertexAI` was deprecated in LangChain 3.2.0 and will be removed in 4.0.0. An updated version of the class exists in the `langchain-google-genai package and should be used instead. To use it run `pip install -U `langchain-google-genai` and import as `from `langchain_google_genai import ChatGoogleGenerativeAI``.\n",
      "  llm = ChatVertexAI(model_name=\"gemini-2.5-flash-lite\")\n"
     ]
    }
   ],
   "source": [
    "llm = ChatVertexAI(model_name=\"gemini-2.5-flash-lite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bafb3b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"human\", \"What is capital of {country}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05d2fb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fca4c4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({'country': 'France'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb9bf8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15b40586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is **Paris**.', additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 10, 'candidates_token_count': 8, 'total_token_count': 18, 'prompt_tokens_details': [{'modality': 1, 'token_count': 10}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 8}], 'thoughts_token_count': 0, 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.0008943912689574063, 'model_provider': 'google_vertexai', 'model_name': 'gemini-2.5-flash-lite'}, id='lc_run--019bfd47-9e31-7d91-9990-c7439a14aaf5-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 10, 'output_tokens': 8, 'total_tokens': 18, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8e8f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I know i want text out which is a string\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "chain_with_output = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1889fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain_with_output.invoke({'country': 'France'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c708fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7f60d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is **Paris**.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6a2704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant responding always in json format\"),\n",
    "    (\"human\", \"What is capital of {country}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "709d1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e459cbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='```json\\n{\\n  \"country\": \"France\",\\n  \"capital\": \"Paris\"\\n}\\n```', additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 15, 'candidates_token_count': 24, 'total_token_count': 39, 'prompt_tokens_details': [{'modality': 1, 'token_count': 15}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 24}], 'thoughts_token_count': 0, 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.001756157570828994, 'model_provider': 'google_vertexai', 'model_name': 'gemini-2.5-flash-lite'}, id='lc_run--019bfd4b-b91e-7953-8124-c0d7692b5f5e-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 15, 'output_tokens': 24, 'total_tokens': 39, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({'country': 'France'})\n",
    "print(type(response))\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a1a67af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "#parser = JsonOutputParser()\n",
    "\n",
    "chain_with_output = prompt | llm | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a89610be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'country': 'France', 'capital': 'Paris'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain_with_output.invoke({'country': 'France'})\n",
    "print(type(response))\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d44691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hello-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
